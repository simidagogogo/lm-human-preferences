{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 2}, "timestamp": 1768058735207}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768058735207}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 2}, "timestamp": 1768058976676}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768058976676}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 1, "nsamples": 1}, "timestamp": 1768059076224}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768059076224}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768059203924}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768059203925}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 8}, "timestamp": 1768059238956}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768059238957}
