{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768098577395}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768098577395}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101469984}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101469984}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101494281}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101494281}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101576115}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101576115}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101604047}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101604047}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101792838}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101792838}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:28", "message": "sample_policy entry", "data": {"save_dir": null, "model_name": "124M", "savescope": "policy", "temperature": 1.0, "seed": null, "batch_size": 2, "nsamples": 4}, "timestamp": 1768101911114}
{"sessionId": "debug-session", "runId": "run1", "hypothesisId": "A", "location": "sample.py:45", "message": "using raw GPT-2 model", "data": {"model_name": "124M"}, "timestamp": 1768101911114}
